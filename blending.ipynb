{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors;\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = True\n",
    "knn = 100\n",
    "ensemble_mode = 'concat'\n",
    "normalize = True\n",
    "model = 'effnetv1_b7_backfin_train_' \n",
    "model_2 = ['effnetv1_b7_backfin_s20m2_', 'effnetv1_b5_subc_backfin_', 'effnetv1_b5_768fullbody_s20m2_', 'effnetv1_b7_600fullbody_s20m2_'] \n",
    "models = 5\n",
    "\n",
    "# 'effnetv1_b7_backfin_train_', effnetv1_b7_backfin_s20m2_ , effnetv1_b5_subc_backfin_\n",
    "# effnetv1_b5_768crop_s20m2_ , effnetv1_b7_cropped_\n",
    "#  effnetv1_b5_768fullbody_s20m2_ , effnetv1_b7_600fullbody_s20m2_\n",
    "\n",
    "if cropped:\n",
    "    with open('./individual_ids.json', \"r\") as f:\n",
    "        int2str = json.loads(f.read())\n",
    "    int2str = {int2str[x]:x for x in int2str}\n",
    "else:\n",
    "    with open('./int2str.json', \"r\") as f:\n",
    "        int2str = json.loads(f.read())\n",
    "\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_train = []\n",
    "df_list_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    with open(f'./embeddings/{model}{i}.npy', 'rb') as fh:\n",
    "        train_ids = np.load(fh)\n",
    "        train_embeddings = np.load(fh)\n",
    "        train_targets = np.load(fh)\n",
    "        test_ids = np.load(fh)\n",
    "        test_embeddings = np.load(fh)\n",
    "    df_train = pd.DataFrame({'ids': train_ids, f'targets_{i}':train_targets, f'embeddings_{i}': np.array_split(train_embeddings, train_embeddings.shape[0])})\n",
    "    df_train.set_index('ids', inplace=True)\n",
    "    df_list_train.append(df_train)\n",
    "    \n",
    "    df_test = pd.DataFrame({'ids': test_ids, f'embeddings_{i}': np.array_split(test_embeddings, test_embeddings.shape[0])})\n",
    "    df_test.set_index('ids', inplace=True)\n",
    "    df_list_test.append(df_test)\n",
    "\n",
    "if model_2 is not None:\n",
    "    df_list_train_2 = []\n",
    "    df_list_test_2 = []\n",
    "\n",
    "    for j, _model_2 in enumerate(model_2):\n",
    "        for i in range(5):\n",
    "            with open(f'./embeddings/{_model_2}{i}.npy', 'rb') as fh:\n",
    "                train_ids = np.load(fh)\n",
    "                train_embeddings = np.load(fh)\n",
    "                train_targets = np.load(fh)\n",
    "                test_ids = np.load(fh)\n",
    "                test_embeddings = np.load(fh)\n",
    "            df_train_2 = pd.DataFrame({'ids': train_ids, f'embeddings_{i+5*(j+1)}': np.array_split(train_embeddings, train_embeddings.shape[0])}) #f'targets_{i}':train_targets, \n",
    "            df_train_2.set_index('ids', inplace=True)\n",
    "            df_list_train.append(df_train_2)\n",
    "            \n",
    "            df_test_2 = pd.DataFrame({'ids': test_ids, f'embeddings_{i+5*(j+1)}': np.array_split(test_embeddings, test_embeddings.shape[0])})\n",
    "            df_test_2.set_index('ids', inplace=True)\n",
    "            df_list_test.append(df_test_2)\n",
    "\n",
    "df_train = df_list_train[0].join(df_list_train[1:])\n",
    "df_train.drop(['targets_1', 'targets_2', 'targets_3', 'targets_4'], axis=1, inplace=True)\n",
    "df_test = df_list_test[0].join(df_list_test[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.squeeze(np.vstack(df_train.index.to_numpy()))\n",
    "train_targets = np.squeeze(np.vstack(df_train['targets_0'].to_numpy()))\n",
    "train_embeddings = []\n",
    "\n",
    "for i in range(5*models):\n",
    "    embeds = np.vstack(df_train[f'embeddings_{i}'].to_numpy())\n",
    "    if normalize:\n",
    "        embeds = normalized(embeds, 0)\n",
    "    train_embeddings.append(embeds)\n",
    "train_embeddings_concat = np.concatenate(train_embeddings, axis=1)\n",
    "train_embeddings_mean = np.mean(np.stack(train_embeddings), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = np.squeeze(np.vstack(df_test.index.to_numpy()))\n",
    "test_embeddings = []\n",
    "for i in range(5*models):\n",
    "    embeds = np.vstack(df_test[f'embeddings_{i}'].to_numpy())\n",
    "    if normalize:\n",
    "        embeds = normalized(embeds, 0)\n",
    "    test_embeddings.append(embeds)\n",
    "test_embeddings_concat = np.concatenate(test_embeddings, axis=1)\n",
    "test_embeddings = np.mean(np.stack(test_embeddings), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ensemble_mode == 'concat':\n",
    "    train_embeddings = train_embeddings_concat\n",
    "    test_embeddings = test_embeddings_concat\n",
    "else:\n",
    "    train_embeddings = train_embeddings_mean\n",
    "    train_targets = train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_embeddings.shape,train_targets.shape)\n",
    "print(test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=knn,metric='cosine')\n",
    "neigh.fit(train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nn_distances = []\n",
    "test_nn_idxs = []\n",
    "for i in tqdm(range(len(test_ids))):\n",
    "    distances,idxs = neigh.kneighbors(np.expand_dims(test_embeddings[i], axis=0), knn, return_distance=True)\n",
    "    test_nn_idxs.append(idxs)\n",
    "    test_nn_distances.append(distances)\n",
    "test_nn_distances = np.concatenate(test_nn_distances)\n",
    "test_nn_idxs = np.concatenate(test_nn_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = []\n",
    "for i in tqdm(range(len(test_ids))):\n",
    "    id_ = test_ids[i]\n",
    "    targets = train_targets[test_nn_idxs[i]]\n",
    "    distances = test_nn_distances[i]\n",
    "    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n",
    "    subset_preds['image'] = id_\n",
    "    test_df.append(subset_preds)\n",
    "test_df = pd.concat(test_df).reset_index(drop=True)\n",
    "test_df['confidence'] = 1-test_df['distances']\n",
    "test_df = test_df.groupby(['image','target']).confidence.max().reset_index()\n",
    "test_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True)\n",
    "test_df['target'] = test_df['target'].map(int2str)\n",
    "test_df.image.value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = ['938b7e931166', '5bf17305f073', '7593d2aee842', '7362d7a01d00','956562ff2888']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.55\n",
    "\n",
    "predictions = {}\n",
    "for i,row in tqdm(test_df.iterrows()):\n",
    "    if row.image in predictions:\n",
    "        if len(predictions[row.image])==5:\n",
    "            continue\n",
    "        elif row.confidence<=threshold: # added\n",
    "            if 'new_individual' not in predictions[row.image]: # added\n",
    "                predictions[row.image].append('new_individual') # added\n",
    "                if len(predictions[row.image])==5: # added\n",
    "                    continue # added\n",
    "        predictions[row.image].append(row.target)\n",
    "    elif row.confidence>threshold:\n",
    "        predictions[row.image] = [row.target,'new_individual'] # modified\n",
    "    else:\n",
    "        predictions[row.image] = ['new_individual',row.target]\n",
    "        \n",
    "for x in tqdm(predictions):\n",
    "    if len(predictions[x])<5:\n",
    "        remaining = [y for y in sample_list if y not in predictions]\n",
    "        predictions[x] = predictions[x]+remaining\n",
    "        predictions[x] = predictions[x][:5]\n",
    "    predictions[x] = ' '.join(predictions[x])\n",
    "    \n",
    "predictions = pd.Series(predictions).reset_index()\n",
    "predictions.columns = ['image','predictions']\n",
    "predictions.to_csv('submission.csv',index=False)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Predictions for Backfin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"submission_55.csv\") #prev submission\n",
    "#whales without backfins determined with a simple classifier\n",
    "ids = np.load(\"ids_without_backfin.npy\", allow_pickle = True) \n",
    "ids2 = df2[\"image\"][~df2[\"image\"].isin(predictions[\"image\"])] #images without a bounding box\n",
    "submission = pd.concat([\n",
    "    predictions[~(predictions[\"image\"].isin(ids))],\n",
    "    df2[df2[\"image\"].isin(ids)],\n",
    "    df2[df2[\"image\"].isin(ids2)]\n",
    "])\n",
    "submission = submission.drop_duplicates()\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6cb187081d668c38147b0f3d97a043504a901c6dcb7870a241b1dabd3f9f1048"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('phd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
